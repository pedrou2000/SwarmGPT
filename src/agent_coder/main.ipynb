{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import constants\n",
    "from human_eval_utils import parse_python_code, construct_test_program, code_runs_without_errors, save_results\n",
    "from generic_agents.CodeInterpreterAgent import CodeInterpreterAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the HumanEval Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n",
      "dict_keys(['task_id', 'prompt', 'canonical_solution', 'test', 'entry_point'])\n",
      "\n",
      "\n",
      "def sort_third(l: list):\n",
      "    \"\"\"This function takes a list l and returns a list l' such that\n",
      "    l' is identical to l in the indicies that are not divisible by three, while its values at the indicies that are divisible by three are equal\n",
      "    to the values of the corresponding indicies of l, but sorted.\n",
      "    >>> sort_third([1, 2, 3])\n",
      "    [1, 2, 3]\n",
      "    >>> sort_third([5, 6, 3, 4, 8, 9, 2])\n",
      "    [2, 6, 3, 4, 8, 9, 5]\n",
      "    \"\"\"\n",
      "\n",
      "sort_third\n"
     ]
    }
   ],
   "source": [
    "from human_eval_utils import load_human_eval\n",
    "\n",
    "dataset = load_human_eval()\n",
    "\n",
    "print(len(dataset))\n",
    "task = dataset[-131]\n",
    "# print a random example\n",
    "print(task.keys())\n",
    "print(task['prompt'])\n",
    "print(task['entry_point'])\n",
    "# print(task['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Agent Coder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CodeInterpreterAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of messages: 0\n",
      "Number of messages: 2\n",
      "Problem 0 - Tests Passed: True\n",
      "AssertionError in check_code_execution: Test 1\n",
      "Number of messages: 2\n",
      "Problem 1 - Tests Passed: False\n",
      "Number of messages: 2\n",
      "Problem 2 - Tests Passed: True\n",
      "Correct: 2/3\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\" \n",
    "    You are an expert software engineer. You are asked to write code to solve a problem \n",
    "    which involves creating a Python method to solve a problem indicated as the comments of the method. \n",
    "    The code should be efficient and correct. The code should be written in Python. \n",
    "    Store the code solution in a file, and provide the file path as the answer.\n",
    "    Do not add any assertions to the code, just complete the method. \n",
    "    Any library imports should be inside the new method, not at the top of the file.\n",
    "\"\"\"\n",
    "\n",
    "n_problems = 3\n",
    "single_agent_output_dir = 'CodeGenerations/single_agent_coder'\n",
    "single_agent_coder = CodeInterpreterAgent(system_prompt=system_prompt, agent_name=\"single_agent_coder\")\n",
    "print(f'Number of messages: {single_agent_coder.get_number_messages()}')\n",
    "\n",
    "\n",
    "run = False\n",
    "if run:\n",
    "    n_correct = 0\n",
    "    for n_problem in range(n_problems):\n",
    "        task = dataset[-n_problem]\n",
    "        \n",
    "        solution_file_path = os.path.join(single_agent_output_dir, f'problem_{n_problem}.py')\n",
    "        test_file_save_path = os.path.join(single_agent_output_dir, f'test_{n_problem}.py')\n",
    "\n",
    "        response = single_agent_coder.prompt_with_output_file(task['prompt'], file_path=solution_file_path)\n",
    "        code_runs = single_agent_coder.test_human_eval_solutions(solution_file_path=solution_file_path, test_code=task['test'], \n",
    "                                            method_name=task['entry_point'], test_file_save_path=test_file_save_path)\n",
    "        \n",
    "        print(f'Number of messages: {single_agent_coder.get_number_messages()}')\n",
    "        print(f'Problem {n_problem} - Tests Passed: {code_runs}')\n",
    "\n",
    "        if code_runs:\n",
    "            n_correct += 1\n",
    "        single_agent_coder.delete_all_messages()\n",
    "\n",
    "    print(f'Correct: {n_correct}/{n_problems}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultiTurnLLMAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generic_agents.MultiTurnLLMAgent import MultiTurnLLMAgent\n",
    "\n",
    "system_prompt = \"\"\" \n",
    "    You are an expert software engineer. You are asked to write code to solve a problem \n",
    "    which involves creating a Python method to solve a problem indicated as the comments of the method. \n",
    "    You should only output the completition of the method, not the entire file.\n",
    "\"\"\"\n",
    "\n",
    "agent = MultiTurnLLMAgent(system_prompt=system_prompt)\n",
    "n_tasks = len(dataset)\n",
    "results = {\n",
    "    \"score\": 0, \n",
    "    \"test_counts\": {\"NoError\": 0, \"Error\": 0, \"AssertionError\": 0, \"IncorrectInput\": 0}, \n",
    "    \"tests_results\": {}\n",
    "}\n",
    "\n",
    "\n",
    "run = False\n",
    "if run:\n",
    "    n_correct = 0\n",
    "    for task_number in range(n_tasks):\n",
    "        task = dataset[task_number]\n",
    "        \n",
    "        response = agent.user_prompt(task['prompt'])\n",
    "        completion = parse_python_code(response)\n",
    "\n",
    "        test_path = constants.HUMAN_EVAL_SINGLE_AGENT_DIR + 'test_files/' + f'problem_{task_number}.py'\n",
    "        test_program = construct_test_program(task['prompt'], completion, task['test'], task['entry_point'], save_path=test_path)\n",
    "        (code_works, reason) = code_runs_without_errors(file_path=test_path)\n",
    "        \n",
    "        print(f'Problem {task_number} - Tests Passed: {code_works}')\n",
    "        if code_works:\n",
    "            n_correct += 1\n",
    "        if reason in results[\"test_counts\"]:\n",
    "            results[\"test_counts\"][reason] += 1\n",
    "        else:\n",
    "            results[\"test_counts\"][reason] = 1\n",
    "        results[\"tests_results\"][task_number] = (code_works, reason)\n",
    "\n",
    "        agent.reset_messages()\n",
    "\n",
    "    results[\"score\"] = round(n_correct/n_tasks * 100, 4)\n",
    "    save_results(results, constants.HUMAN_EVAL_SINGLE_AGENT_DIR)\n",
    "    print(f'Correct: {n_correct}/{n_tasks}')\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain AgentCoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Initializing CodeInterpreterAgent with thread id:  Thread(id='thread_XZlltz91djzcqFsibbzbW1ov', created_at=1722323714, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None)) \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from multi_agent_graph import get_multi_agent_summarizer_graph\n",
    "from IPython.display import Image, display\n",
    "\n",
    "graph = get_multi_agent_summarizer_graph()\n",
    "app = graph.compile()\n",
    "# display(Image(app.get_graph(xray=True).draw_mermaid_png())) \n",
    "\n",
    "def agent_coder(task_prompt, max_iterations=3, passed_tests_threshold=0.7):\n",
    "    config = {\"recursion_limit\": 50}\n",
    "    inputs = {\n",
    "        \"incomplete_method\": task_prompt,\n",
    "        \"max_iterations\": max_iterations,\n",
    "        \"passed_tests_threshold\": passed_tests_threshold,\n",
    "    }\n",
    "\n",
    "    for event in app.stream(inputs, config=config):\n",
    "        print(\"Event:\", event)\n",
    "\n",
    "    \n",
    "    last_event_name = list(event.keys())[0]\n",
    "    return event[last_event_name]['completed_method']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In AgentTestGenerator\n",
      "Event: {'Test Generator': {'incomplete_method': 'from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n', 'generated_tests': '\\nassert has_close_elements([1.0, 2.0, 3.0], 0.5) == False, \"Test Case 1: No two elements are closer than 0.5\"\\nassert has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3) == True, \"Test Case 2: 2.8 and 2.0 are closer than 0.3\"\\nassert has_close_elements([1.0, 1.4, 2.0], 0.5) == True, \"Test Case 3: 1.0 and 1.4 are closer than 0.5\"\\nassert has_close_elements([], 0.5) == False, \"Test Case 4: Empty list should return False\"\\nassert has_close_elements([1.0], 0.5) == False, \"Test Case 5: Single element should return False\"\\nassert has_close_elements([1.0, 1.5, 2.0], 0.4) == True, \"Test Case 6: 1.0 and 1.5 are closer than 0.4\"\\nassert has_close_elements([-1.0, -1.2, 0.0], 0.3) == True, \"Test Case 7: -1.0 and -1.2 are closer than 0.3\"\\nassert has_close_elements([1.0, 2.0, 3.0, 4.0, 5.0], 1.0) == True, \"Test Case 8: 1.0 and 2.0 are closer than 1.0\"\\nassert has_close_elements([10.0, 9.5, 8.0, 7.0], 0.6) == True, \"Test Case 9: 10.0 and 9.5 are closer than 0.6\"\\nassert has_close_elements([5.0, 5.1, 5.2], 0.2) == True, \"Test Case 10: 5.0 and 5.1 are closer than 0.2\"\\n', 'max_iterations': 3, 'passed_tests_threshold': 0.7}}\n",
      "In AgentCoder\n",
      "Event: {'Coder': {'incomplete_method': 'from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n', 'generated_tests': '\\nassert has_close_elements([1.0, 2.0, 3.0], 0.5) == False, \"Test Case 1: No two elements are closer than 0.5\"\\nassert has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3) == True, \"Test Case 2: 2.8 and 2.0 are closer than 0.3\"\\nassert has_close_elements([1.0, 1.4, 2.0], 0.5) == True, \"Test Case 3: 1.0 and 1.4 are closer than 0.5\"\\nassert has_close_elements([], 0.5) == False, \"Test Case 4: Empty list should return False\"\\nassert has_close_elements([1.0], 0.5) == False, \"Test Case 5: Single element should return False\"\\nassert has_close_elements([1.0, 1.5, 2.0], 0.4) == True, \"Test Case 6: 1.0 and 1.5 are closer than 0.4\"\\nassert has_close_elements([-1.0, -1.2, 0.0], 0.3) == True, \"Test Case 7: -1.0 and -1.2 are closer than 0.3\"\\nassert has_close_elements([1.0, 2.0, 3.0, 4.0, 5.0], 1.0) == True, \"Test Case 8: 1.0 and 2.0 are closer than 1.0\"\\nassert has_close_elements([10.0, 9.5, 8.0, 7.0], 0.6) == True, \"Test Case 9: 10.0 and 9.5 are closer than 0.6\"\\nassert has_close_elements([5.0, 5.1, 5.2], 0.2) == True, \"Test Case 10: 5.0 and 5.1 are closer than 0.2\"\\n', 'completed_method': '\\nfrom typing import List\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n    for idx, elem in enumerate(numbers):\\n        for idx2, elem2 in enumerate(numbers):\\n            if idx != idx2:  # Ensure we are not comparing the same element\\n                distance = abs(elem - elem2)\\n                if distance < threshold:\\n                    return True\\n    return False\\n', 'max_iterations': 3, 'passed_tests_threshold': 0.7}}\n",
      "In AgentTestExecutor, with thread id:  Thread(id='thread_XZlltz91djzcqFsibbzbW1ov', created_at=1722323714, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))\n",
      "Current iterations: 1\n",
      "Tests passed: True. Proportion tests passed: 0.9\n",
      "Feedback: \n",
      "The code fails to pass all test cases. Specifically, it failed at:\n",
      "\n",
      "- **Test Case 6:** The assertion for `has_close_elements([1.0, 1.5, 2.0], 0.4)` expected a return value of `True`, but the function returned `False`. \n",
      "\n",
      "Therefore, the result indicates that not all test cases are passing.\n",
      "Event: {'Test Executor': {'incomplete_method': 'from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n', 'generated_tests': '\\nassert has_close_elements([1.0, 2.0, 3.0], 0.5) == False, \"Test Case 1: No two elements are closer than 0.5\"\\nassert has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3) == True, \"Test Case 2: 2.8 and 2.0 are closer than 0.3\"\\nassert has_close_elements([1.0, 1.4, 2.0], 0.5) == True, \"Test Case 3: 1.0 and 1.4 are closer than 0.5\"\\nassert has_close_elements([], 0.5) == False, \"Test Case 4: Empty list should return False\"\\nassert has_close_elements([1.0], 0.5) == False, \"Test Case 5: Single element should return False\"\\nassert has_close_elements([1.0, 1.5, 2.0], 0.4) == True, \"Test Case 6: 1.0 and 1.5 are closer than 0.4\"\\nassert has_close_elements([-1.0, -1.2, 0.0], 0.3) == True, \"Test Case 7: -1.0 and -1.2 are closer than 0.3\"\\nassert has_close_elements([1.0, 2.0, 3.0, 4.0, 5.0], 1.0) == True, \"Test Case 8: 1.0 and 2.0 are closer than 1.0\"\\nassert has_close_elements([10.0, 9.5, 8.0, 7.0], 0.6) == True, \"Test Case 9: 10.0 and 9.5 are closer than 0.6\"\\nassert has_close_elements([5.0, 5.1, 5.2], 0.2) == True, \"Test Case 10: 5.0 and 5.1 are closer than 0.2\"\\n', 'completed_method': '\\nfrom typing import List\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n    for idx, elem in enumerate(numbers):\\n        for idx2, elem2 in enumerate(numbers):\\n            if idx != idx2:  # Ensure we are not comparing the same element\\n                distance = abs(elem - elem2)\\n                if distance < threshold:\\n                    return True\\n    return False\\n', 'tests_passed': True, 'feedback': 'The code fails to pass all test cases. Specifically, it failed at:\\n\\n- **Test Case 6:** The assertion for `has_close_elements([1.0, 1.5, 2.0], 0.4)` expected a return value of `True`, but the function returned `False`. \\n\\nTherefore, the result indicates that not all test cases are passing.', 'current_iterations': 1, 'max_iterations': 3, 'passed_tests_threshold': 0.7}}\n",
      "Problem 0 - Tests Passed: True - Reason: \n",
      "In AgentTestGenerator\n",
      "Event: {'Test Generator': {'incomplete_method': 'from typing import List\\n\\n\\ndef separate_paren_groups(paren_string: str) -> List[str]:\\n    \"\"\" Input to this function is a string containing multiple groups of nested parentheses. Your goal is to\\n    separate those group into separate strings and return the list of those.\\n    Separate groups are balanced (each open brace is properly closed) and not nested within each other\\n    Ignore any spaces in the input string.\\n    >>> separate_paren_groups(\\'( ) (( )) (( )( ))\\')\\n    [\\'()\\', \\'(())\\', \\'(()())\\']\\n    \"\"\"\\n', 'generated_tests': '\\nassert separate_paren_groups(\\'( ) (( )) (( )( ))\\') == [\\'()\\', \\'(())\\', \\'(()())\\'], \"Test Case 1: Basic test with multiple groups of parentheses\"\\nassert separate_paren_groups(\\'() (())\\') == [\\'()\\', \\'(())\\'], \"Test Case 2: Simple test with no spaces and two groups\"\\nassert separate_paren_groups(\\'((())) ()\\') == [\\'((()))\\', \\'()\\'], \"Test Case 3: Test with nested group and a separate group\"\\nassert separate_paren_groups(\\'()()()\\') == [\\'()\\', \\'()\\', \\'()\\'], \"Test Case 4: Test with multiple non-nested groups\"\\nassert separate_paren_groups(\\'( ) ( )\\') == [\\'()\\', \\'()\\'], \"Test Case 5: Test with spaces between parentheses\"\\nassert separate_paren_groups(\\'(((( ))))\\') == [\\'((()))\\'], \"Test Case 6: Test with deeply nested parentheses\"\\nassert separate_paren_groups(\\'\\') == [], \"Test Case 7: Test with empty string\"\\nassert separate_paren_groups(\\'((( ) ) (( )) )\\') == [\\'(())\\', \\'(())\\'], \"Test Case 8: Test with a mix of nested and separate groups\"\\nassert separate_paren_groups(\\'() ( ( ) ( ) )\\') == [\\'()\\', \\'()\\', \\'()\\', \\'()\\'], \"Test Case 9: Test with multiple nested groups and separate groups\"\\nassert separate_paren_groups(\\'   ( )   ((  ))   ( (   ) ( ) )   \\') == [\\'()\\', \\'(())\\', \\'(()())\\'], \"Test Case 10: Test with leading and trailing spaces\"\\n', 'max_iterations': 3, 'passed_tests_threshold': 0.7}}\n",
      "In AgentCoder\n",
      "Event: {'Coder': {'incomplete_method': 'from typing import List\\n\\n\\ndef separate_paren_groups(paren_string: str) -> List[str]:\\n    \"\"\" Input to this function is a string containing multiple groups of nested parentheses. Your goal is to\\n    separate those group into separate strings and return the list of those.\\n    Separate groups are balanced (each open brace is properly closed) and not nested within each other\\n    Ignore any spaces in the input string.\\n    >>> separate_paren_groups(\\'( ) (( )) (( )( ))\\')\\n    [\\'()\\', \\'(())\\', \\'(()())\\']\\n    \"\"\"\\n', 'generated_tests': '\\nassert separate_paren_groups(\\'( ) (( )) (( )( ))\\') == [\\'()\\', \\'(())\\', \\'(()())\\'], \"Test Case 1: Basic test with multiple groups of parentheses\"\\nassert separate_paren_groups(\\'() (())\\') == [\\'()\\', \\'(())\\'], \"Test Case 2: Simple test with no spaces and two groups\"\\nassert separate_paren_groups(\\'((())) ()\\') == [\\'((()))\\', \\'()\\'], \"Test Case 3: Test with nested group and a separate group\"\\nassert separate_paren_groups(\\'()()()\\') == [\\'()\\', \\'()\\', \\'()\\'], \"Test Case 4: Test with multiple non-nested groups\"\\nassert separate_paren_groups(\\'( ) ( )\\') == [\\'()\\', \\'()\\'], \"Test Case 5: Test with spaces between parentheses\"\\nassert separate_paren_groups(\\'(((( ))))\\') == [\\'((()))\\'], \"Test Case 6: Test with deeply nested parentheses\"\\nassert separate_paren_groups(\\'\\') == [], \"Test Case 7: Test with empty string\"\\nassert separate_paren_groups(\\'((( ) ) (( )) )\\') == [\\'(())\\', \\'(())\\'], \"Test Case 8: Test with a mix of nested and separate groups\"\\nassert separate_paren_groups(\\'() ( ( ) ( ) )\\') == [\\'()\\', \\'()\\', \\'()\\', \\'()\\'], \"Test Case 9: Test with multiple nested groups and separate groups\"\\nassert separate_paren_groups(\\'   ( )   ((  ))   ( (   ) ( ) )   \\') == [\\'()\\', \\'(())\\', \\'(()())\\'], \"Test Case 10: Test with leading and trailing spaces\"\\n', 'completed_method': '\\nfrom typing import List\\n\\ndef separate_paren_groups(paren_string: str) -> List[str]:\\n    result = []\\n    current_string = \"\"\\n    current_depth = 0\\n\\n    for char in paren_string:\\n        if char == \\' \\':\\n            continue  # Ignore spaces\\n        if char == \\'(\\':\\n            current_depth += 1\\n            current_string += char\\n        elif char == \\')\\':\\n            current_depth -= 1\\n            current_string += char\\n            if current_depth == 0:\\n                result.append(current_string)\\n                current_string = \"\"  # Reset for the next group\\n\\n    return result\\n', 'max_iterations': 3, 'passed_tests_threshold': 0.7}}\n",
      "In AgentTestExecutor, with thread id:  Thread(id='thread_XZlltz91djzcqFsibbzbW1ov', created_at=1722323714, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))\n",
      "Current iterations: 1\n",
      "Tests passed: True. Proportion tests passed: 0.9\n",
      "Feedback: \n",
      "The code provided did not pass all the tests. Specifically, it failed the following case:\n",
      "\n",
      "- **Test Case 6**: The input was `(((( ))))` and the expected output was `['((()))']`. \n",
      "\n",
      "The assertion did not hold, leading to an `AssertionError`. \n",
      "\n",
      "If you'd like, I can assist further by looking into why that specific test case failed.\n",
      "Event: {'Test Executor': {'incomplete_method': 'from typing import List\\n\\n\\ndef separate_paren_groups(paren_string: str) -> List[str]:\\n    \"\"\" Input to this function is a string containing multiple groups of nested parentheses. Your goal is to\\n    separate those group into separate strings and return the list of those.\\n    Separate groups are balanced (each open brace is properly closed) and not nested within each other\\n    Ignore any spaces in the input string.\\n    >>> separate_paren_groups(\\'( ) (( )) (( )( ))\\')\\n    [\\'()\\', \\'(())\\', \\'(()())\\']\\n    \"\"\"\\n', 'generated_tests': '\\nassert separate_paren_groups(\\'( ) (( )) (( )( ))\\') == [\\'()\\', \\'(())\\', \\'(()())\\'], \"Test Case 1: Basic test with multiple groups of parentheses\"\\nassert separate_paren_groups(\\'() (())\\') == [\\'()\\', \\'(())\\'], \"Test Case 2: Simple test with no spaces and two groups\"\\nassert separate_paren_groups(\\'((())) ()\\') == [\\'((()))\\', \\'()\\'], \"Test Case 3: Test with nested group and a separate group\"\\nassert separate_paren_groups(\\'()()()\\') == [\\'()\\', \\'()\\', \\'()\\'], \"Test Case 4: Test with multiple non-nested groups\"\\nassert separate_paren_groups(\\'( ) ( )\\') == [\\'()\\', \\'()\\'], \"Test Case 5: Test with spaces between parentheses\"\\nassert separate_paren_groups(\\'(((( ))))\\') == [\\'((()))\\'], \"Test Case 6: Test with deeply nested parentheses\"\\nassert separate_paren_groups(\\'\\') == [], \"Test Case 7: Test with empty string\"\\nassert separate_paren_groups(\\'((( ) ) (( )) )\\') == [\\'(())\\', \\'(())\\'], \"Test Case 8: Test with a mix of nested and separate groups\"\\nassert separate_paren_groups(\\'() ( ( ) ( ) )\\') == [\\'()\\', \\'()\\', \\'()\\', \\'()\\'], \"Test Case 9: Test with multiple nested groups and separate groups\"\\nassert separate_paren_groups(\\'   ( )   ((  ))   ( (   ) ( ) )   \\') == [\\'()\\', \\'(())\\', \\'(()())\\'], \"Test Case 10: Test with leading and trailing spaces\"\\n', 'completed_method': '\\nfrom typing import List\\n\\ndef separate_paren_groups(paren_string: str) -> List[str]:\\n    result = []\\n    current_string = \"\"\\n    current_depth = 0\\n\\n    for char in paren_string:\\n        if char == \\' \\':\\n            continue  # Ignore spaces\\n        if char == \\'(\\':\\n            current_depth += 1\\n            current_string += char\\n        elif char == \\')\\':\\n            current_depth -= 1\\n            current_string += char\\n            if current_depth == 0:\\n                result.append(current_string)\\n                current_string = \"\"  # Reset for the next group\\n\\n    return result\\n', 'tests_passed': True, 'feedback': \"The code provided did not pass all the tests. Specifically, it failed the following case:\\n\\n- **Test Case 6**: The input was `(((( ))))` and the expected output was `['((()))']`. \\n\\nThe assertion did not hold, leading to an `AssertionError`. \\n\\nIf you'd like, I can assist further by looking into why that specific test case failed.\", 'current_iterations': 1, 'max_iterations': 3, 'passed_tests_threshold': 0.7}}\n",
      "Problem 1 - Tests Passed: True - Reason: \n",
      "In AgentTestGenerator\n",
      "Event: {'Test Generator': {'incomplete_method': '\\n\\ndef truncate_number(number: float) -> float:\\n    \"\"\" Given a positive floating point number, it can be decomposed into\\n    and integer part (largest integer smaller than given number) and decimals\\n    (leftover part always smaller than 1).\\n\\n    Return the decimal part of the number.\\n    >>> truncate_number(3.5)\\n    0.5\\n    \"\"\"\\n', 'generated_tests': '\\nassert truncate_number(3.5) == 0.5, \"Test Case 1: Check decimal part of 3.5\"\\nassert truncate_number(2.75) == 0.75, \"Test Case 2: Check decimal part of 2.75\"\\nassert truncate_number(5.0) == 0.0, \"Test Case 3: Check decimal part of 5.0 (no decimal part)\"\\nassert truncate_number(0.99) == 0.99, \"Test Case 4: Check decimal part of 0.99\"\\nassert truncate_number(10.123) == 0.123, \"Test Case 5: Check decimal part of 10.123\"\\nassert truncate_number(7.8567) == 0.8567, \"Test Case 6: Check decimal part of 7.8567\"\\n', 'max_iterations': 3, 'passed_tests_threshold': 0.7}}\n",
      "In AgentCoder\n",
      "Event: {'Coder': {'incomplete_method': '\\n\\ndef truncate_number(number: float) -> float:\\n    \"\"\" Given a positive floating point number, it can be decomposed into\\n    and integer part (largest integer smaller than given number) and decimals\\n    (leftover part always smaller than 1).\\n\\n    Return the decimal part of the number.\\n    >>> truncate_number(3.5)\\n    0.5\\n    \"\"\"\\n', 'generated_tests': '\\nassert truncate_number(3.5) == 0.5, \"Test Case 1: Check decimal part of 3.5\"\\nassert truncate_number(2.75) == 0.75, \"Test Case 2: Check decimal part of 2.75\"\\nassert truncate_number(5.0) == 0.0, \"Test Case 3: Check decimal part of 5.0 (no decimal part)\"\\nassert truncate_number(0.99) == 0.99, \"Test Case 4: Check decimal part of 0.99\"\\nassert truncate_number(10.123) == 0.123, \"Test Case 5: Check decimal part of 10.123\"\\nassert truncate_number(7.8567) == 0.8567, \"Test Case 6: Check decimal part of 7.8567\"\\n', 'completed_method': '\\ndef truncate_number(number: float) -> float:\\n    \"\"\" Given a positive floating point number, it can be decomposed into\\n    and integer part (largest integer smaller than given number) and decimals\\n    (leftover part always smaller than 1).\\n    \\n    Return the decimal part of the number.\\n    >>> truncate_number(3.5)\\n    0.5\\n    \"\"\"\\n    integer_part = int(number)  # Get the integer part\\n    decimal_part = number - integer_part  # Calculate the decimal part\\n    return decimal_part  # Return the decimal part\\n', 'max_iterations': 3, 'passed_tests_threshold': 0.7}}\n",
      "In AgentTestExecutor, with thread id:  Thread(id='thread_XZlltz91djzcqFsibbzbW1ov', created_at=1722323714, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))\n",
      "Current iterations: 1\n",
      "Tests passed: True. Proportion tests passed: 0.8333333333333334\n",
      "Feedback: \n",
      "The code failed to pass the tests. Specifically, it raised an `AssertionError` for Test Case 5, which checks the decimal part of 10.123. This indicates that the function may not be returning the expected result for this input. All other test cases seemed to pass prior to this failure.\n",
      "Event: {'Test Executor': {'incomplete_method': '\\n\\ndef truncate_number(number: float) -> float:\\n    \"\"\" Given a positive floating point number, it can be decomposed into\\n    and integer part (largest integer smaller than given number) and decimals\\n    (leftover part always smaller than 1).\\n\\n    Return the decimal part of the number.\\n    >>> truncate_number(3.5)\\n    0.5\\n    \"\"\"\\n', 'generated_tests': '\\nassert truncate_number(3.5) == 0.5, \"Test Case 1: Check decimal part of 3.5\"\\nassert truncate_number(2.75) == 0.75, \"Test Case 2: Check decimal part of 2.75\"\\nassert truncate_number(5.0) == 0.0, \"Test Case 3: Check decimal part of 5.0 (no decimal part)\"\\nassert truncate_number(0.99) == 0.99, \"Test Case 4: Check decimal part of 0.99\"\\nassert truncate_number(10.123) == 0.123, \"Test Case 5: Check decimal part of 10.123\"\\nassert truncate_number(7.8567) == 0.8567, \"Test Case 6: Check decimal part of 7.8567\"\\n', 'completed_method': '\\ndef truncate_number(number: float) -> float:\\n    \"\"\" Given a positive floating point number, it can be decomposed into\\n    and integer part (largest integer smaller than given number) and decimals\\n    (leftover part always smaller than 1).\\n    \\n    Return the decimal part of the number.\\n    >>> truncate_number(3.5)\\n    0.5\\n    \"\"\"\\n    integer_part = int(number)  # Get the integer part\\n    decimal_part = number - integer_part  # Calculate the decimal part\\n    return decimal_part  # Return the decimal part\\n', 'tests_passed': True, 'feedback': 'The code failed to pass the tests. Specifically, it raised an `AssertionError` for Test Case 5, which checks the decimal part of 10.123. This indicates that the function may not be returning the expected result for this input. All other test cases seemed to pass prior to this failure.', 'current_iterations': 1, 'max_iterations': 3, 'passed_tests_threshold': 0.7}}\n",
      "Problem 2 - Tests Passed: True - Reason: \n",
      "Correct: 3/3\n",
      "{'score': 100.0, 'test_counts': {'NoError': 3, 'Error': 0, 'AssertionError': 0, 'IncorrectInput': 0}, 'tests_results': {0: (True, 'NoError'), 1: (True, 'NoError'), 2: (True, 'NoError')}}\n"
     ]
    }
   ],
   "source": [
    "n_tasks = 3\n",
    "passed_tests_threshold = 0.7\n",
    "max_iterations = 3\n",
    "\n",
    "results = {\n",
    "    \"score\": 0, \n",
    "    \"test_counts\": {\"NoError\": 0, \"Error\": 0, \"AssertionError\": 0, \"IncorrectInput\": 0}, \n",
    "    \"tests_results\": {}\n",
    "}\n",
    "\n",
    "n_correct = 0\n",
    "for task_number in range(n_tasks):\n",
    "    task = dataset[task_number]\n",
    "    \n",
    "    completion = agent_coder(task['prompt'], max_iterations=max_iterations, passed_tests_threshold=passed_tests_threshold)\n",
    "\n",
    "    test_path = constants.HUMAN_EVAL_AGENT_CODER_DIR + 'test_files/' + f'problem_{task_number}.py'\n",
    "    test_program = construct_test_program(task['prompt'], completion, task['test'], task['entry_point'], save_path=test_path)\n",
    "    (code_works, reason) = code_runs_without_errors(file_path=test_path)\n",
    "    \n",
    "    print(f'Problem {task_number} - Tests Passed: {code_works}' + f' - Reason: {reason if not code_works else \"\"}')\n",
    "    if code_works:\n",
    "        n_correct += 1\n",
    "    if reason in results[\"test_counts\"]:\n",
    "        results[\"test_counts\"][reason] += 1\n",
    "    else:\n",
    "        results[\"test_counts\"][reason] = 1\n",
    "    results[\"tests_results\"][task_number] = (code_works, reason)\n",
    "\n",
    "results[\"score\"] = round(n_correct/n_tasks * 100, 4)\n",
    "# save_results(results, constants.HUMAN_EVAL_AGENT_CODER_DIR)\n",
    "print(f'Correct: {n_correct}/{n_tasks}')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In AgentTestExecutor, with thread id:  Thread(id='thread_B9l9Ksth8fkj0yttxelVHWrq', created_at=1722098902, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))\n",
      "Current iterations: 1\n",
      "Tests passed: False. Proportion tests passed: 0.0\n",
      "Feedback: \n",
      "The code fails the test. The assertion `assert sum_x_y(1, 2) == -3` is not satisfied, as the actual output of `sum_x_y(1, 2)` is `3`.\n",
      "In AgentTestExecutor, with thread id:  Thread(id='thread_B9l9Ksth8fkj0yttxelVHWrq', created_at=1722098902, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))\n",
      "Current iterations: 2\n",
      "Tests passed: False. Proportion tests passed: 0.0\n",
      "Feedback: \n",
      "The assertion `assert sum_x_y(1, 2) == -3` is not satisfied, as the actual output of `sum_x_y(1, 2)` is `3`.\n",
      "In AgentTestExecutor, with thread id:  Thread(id='thread_B9l9Ksth8fkj0yttxelVHWrq', created_at=1722098902, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))\n",
      "Current iterations: 3\n",
      "Tests passed: False. Proportion tests passed: 0.0\n",
      "Feedback: \n",
      "The code fails the test. The assertion `assert sum_x_y(1, 2) == -3` is not satisfied, as the actual output of `sum_x_y(1, 2)` is `3`.\n",
      "In AgentTestExecutor, with thread id:  Thread(id='thread_B9l9Ksth8fkj0yttxelVHWrq', created_at=1722098902, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))\n",
      "Current iterations: 4\n",
      "Tests passed: False. Proportion tests passed: 0.0\n",
      "Feedback: \n",
      "The code fails the test. The assertion `assert sum_x_y(1, 2) == -3` is not satisfied, as the actual output of `sum_x_y(1, 2)` is `3`.\n",
      "In AgentTestExecutor, with thread id:  Thread(id='thread_B9l9Ksth8fkj0yttxelVHWrq', created_at=1722098902, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))\n",
      "Current iterations: 5\n",
      "Tests passed: False. Proportion tests passed: 0.0\n",
      "Feedback: \n",
      "The code fails the test. The assertion `assert sum_x_y(1, 2) == -3` is not satisfied, as the actual output of `sum_x_y(1, 2)` is `3`.\n"
     ]
    }
   ],
   "source": [
    "from llm_agents.AgentTestExecutor import AgentTestExecutor\n",
    "from data_classes.AgentCoderState import AgentCoderState\n",
    "state = AgentCoderState(completed_method='def sum_x_y():\\n    return x + y\\n', generated_tests='assert sum_x_y(1, 2) == -3', passed_tests_threshold=0.7, max_iterations=3, current_iterations=0)\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    test_executor = AgentTestExecutor()\n",
    "    macm_state = test_executor(state)\n",
    "    test_executor.delete_all_messages()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
